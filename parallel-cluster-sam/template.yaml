AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: >
  Create a new parallel cluster


Parameters:

  ScriptUrl:
    Description: URL to the script to run on the head node. /scripts/cluster-config.sh
    Type: String


  FirstAZPrivateSubnetId:
    Description: The ID of the first private subnet in the first availability zone.
    Type: AWS::EC2::Subnet::Id


  KeyName:
    Description: KeyPair to login to the head node
    Type: AWS::EC2::KeyPair::KeyName
    AllowedPattern: ".+"  # Required

  HeadNodeInstanceType:
    Description: Headnode instance type
    Type: String
    AllowedValues: [m6i.xlarge, m6i.2xlarge, m7i.xlarge, m7i.2xlarge]

  ComputeNodeSubnets:
    Description: List of subnets for compute nodes, joined by comma
    Type: String

  DatabaseClientSecGroup:
    Type: AWS::EC2::SecurityGroup::Id

  HeadNodeSecGroup:
    Type: AWS::EC2::SecurityGroup::Id

  ComputeNodeSecGroup:
    Type: AWS::EC2::SecurityGroup::Id

  VizBackendSecGroup:
    Type: AWS::EC2::SecurityGroup::Id

  DatabaseUri:
    Type: String
    Default: slurm-accounting-cluster.cluster-c2oelv7l4dpl.us-east-1.rds.amazonaws.com
    Description: Uri pointing to database cluster

  DatabaseAdmin:
    Type: String
    Description: Admin username
    Default: clusteradmin

  DatabasePasswordSecretArn:
    Type: String
    Description: Amin password Secret ARN
    NoEcho: true

  ADDomain:
    Type: String
    Description: Active directory domain
    Default: tandemai.com

  ADAddr:
    Type: String
    Description: Active directory address
    Default: ldap://company.com

  ADPasswordSecretArn:
    Type: String
    Description: Active directory secret ARN
    NoEcho: true

  ADReadonlyUser:
    Type: String
    Description: read only user from active directory
    Default: CN=ReadOnlyUser

  EFSFileSystemId:
    Type: String
    Description: shared file system - efs - for software. Empty will mount nothing

  HeadNodeRootVolumeSize:
    Type: Number
    Description: Size of root volume in headnode
    Default: 200

  HeadNodeRootVolumeEncrypted:
    Type: String
    Description: whether head node volume is encrpted
    Default: true
    AllowedValues: [true, false]

  ComputeNodeRootVolumeType:
    Type: String
    Description: type of root volume
    Default: gp3
    AllowedValues: [io1, io2, gp3]

  ComputeNodeRootVolumeSize:
    Type: Number
    Description: Size of root volume in headnode
    Default: 150

  ComputeNodeRootVolumeEncrypted:
    Type: String
    Description: whether head node volume is encrpted
    Default: true
    AllowedValues: [true, false]

  HeadNodeRootVolumeType:
    Type: String
    Description: type of root volume
    Default: gp3
    AllowedValues: [io1, io2, gp3]

  CpuQueueNodeType:
    Type: String
    Description: Node type of CPU queue
    Default: c6i.2xlarge
    AllowedValues: [c6i.2xlarge, c6i.4xlarge, c6i.8xlarge, c6i.16xlarge, c6i.metal, c7i.2xlarge, c7i.4xlarge, c7i.8xlarge, c7i.16xlarge, c7i.48xlarge]

  CpuQueueNodesMax:
    Type: Number
    Description: Max number of nodes
    Default: 10

  LightGpuQueueNodeType:
    Type: String
    Description: Node type of light GPU queue
    Default: g4dn.xlarge
    AllowedValues: [g4dn.xlarge, g4dn.2xlarge, g4dn.4xlarge]

  LightGpuQueueNodesMax:
    Type: Number
    Description: Max number of nodes
    Default: 10

  DebugQueueGPUNodeType:
    Type: String
    Description: Node type of light GPU queue
    Default: g4dn.xlarge
    AllowedValues: [g4dn.xlarge]

  DebugQueueGPUNodeMax:
    Type: Number
    Description: Maximum number of GPU nodes in debug queue
    Default: 2

  DebugQueueCPUNodeType:
    Type: String
    Description: Node type of light GPU queue
    Default: c6i.xlarge
    AllowedValues: [c6i.xlarge, c6i.2xlarge, c6i.4xlarge, c6i.8xlarge, c7i.xlarge, c7i.2xlarge, c7i.4xlarge, c7i.8xlarge]

  DebugQueueCPUNodesMax:
    Type: Number
    Description: Max number of nodes for debug in the cpu section
    Default: 5

  ProjectQueueCpuNodeType:
    Type: String
    Description: Node type of CPU queue
    Default: c6i.2xlarge
    AllowedValues: [c6i.2xlarge, c6i.4xlarge, c6i.8xlarge, c6i.16xlarge, c6i.metal, c7i.2xlarge, c7i.4xlarge, c7i.8xlarge, c7i.16xlarge, c7i.48xlarge]

  ProjectQueueCpuNodesMax:
    Type: Number
    Description: Max number of nodes
    Default: 10

  ProjectQueueGpuNodeType:
    Type: String
    Description: Node type of GPU queue - be careful with p4d.24xlarge
    Default: g4dn.12xlarge
    AllowedValues: [g4dn.xlarge, g4dn.12xlarge, g4dn.metal, p3.2xlarge, p3.8xlarge, p3.16xlarge, p4d.24xlarge, p5.48xlarge, g5.xlarge, g5.12xlarge, g5.48xlarge]

  ProjectQueueGpuNodesMax:
    Type: Number
    Description: Max number of nodes
    Default: 10

  ClusterName:
    Type: String
    Default: "tcluster"
    Description: "Name of the parallel cluster"
    AllowedPattern: ".+"
    MinLength: 2
    MaxLength: 20

  CustomAmiId:
    Description: Custom AMI of the image
    Type: 'AWS::EC2::Image::Id'

  ParallelClusterClusterPolicy:
    Type: String
    Description: ARN of the policy for parallel cluster

  ParallelClusterIamAdminPolicy:
    Type: String
    Description: ARN of the policy for Iam admin

  EventsPolicy:
    Type: String
    Description: ARN of the policy for events

Conditions:
  GovCloud: !Equals [!Ref AWS::Partition, 'aws-us-gov']
  China: !Equals [!Ref AWS::Partition, 'aws-cn']

Resources:
  PclusterLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Action: sts:AssumeRole
            Principal:
              Service: lambda.amazonaws.com
      ManagedPolicyArns: !Split
        - ","
        - !Sub
          - ${LambdaExecutionPolicy},${ClusterPolicy},${DefaultAdminPolicy},${EventsPolicy},${S3Policy}
          - { LambdaExecutionPolicy: !Sub "arn:${AWS::Partition}:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole",
              ClusterPolicy: !Ref ParallelClusterClusterPolicy ,
              DefaultAdminPolicy: !Ref ParallelClusterIamAdminPolicy,
              EventsPolicy: !Ref EventsPolicy,
              S3Policy: !Ref S3Policy }

  PclusterCustomResourceBucket:
    Type: AWS::S3::Bucket

  S3Policy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: S3Policy
            Effect: Allow
            Action:
              - s3:*Object
              - s3:ListBucket
              - s3:ListBucketVersions
            Resource:
              - !Sub arn:${AWS::Partition}:s3:::${PclusterCustomResourceBucket}/*
              - !Sub arn:${AWS::Partition}:s3:::${PclusterCustomResourceBucket}

  PclusterCfnFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain
    Properties:
      RetentionInDays: 90
      LogGroupName: !Sub /aws/lambda/${PclusterCfnFunction}


  PclusterLayer:
    Type: AWS::Lambda::LayerVersion
    Properties:
      # LayerName: !Sub
      #   - PCLayer-${StackIdSuffix}
      #   - { StackIdSuffix: !Select [2, !Split ['/', !Ref 'AWS::StackId']] }
      Description: Library which contains aws-parallelcluster python package and dependencies
      Content:
        S3Bucket: tandemaiserverless
        S3Key: "master/lambda-layer-pcluster-361.zip"
      CompatibleRuntimes:
        - python3.9

  PclusterCfnFunction:
    Type: AWS::Lambda::Function
    Properties:
      Tags:
        - Key: "parallelcluster:version"
          Value: "3.6.1"
        - Key: "parallelcluster:custom_resource"
          Value: "cluster"
      # FunctionName: !Sub
      #   - pcluster-cfn-${StackIdSuffix}
      #   - { StackIdSuffix: !Select [2, !Split ['/', !Ref 'AWS::StackId']] }
      TracingConfig:
        Mode: Active
      MemorySize: 2048
      Timeout: 60
      Handler: index.handler
      Runtime: python3.9
      Role: !GetAtt PclusterLambdaRole.Arn
      Layers:
        - !Ref PclusterLayer
      Code:
        ZipFile: !Sub |
          import boto3
          import cfnresponse
          import datetime
          import json
          import logging
          import os
          import random
          import re
          import string
          import sys
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          import pcluster.api.controllers.cluster_operations_controller
          import pcluster.api.errors
          import pcluster.utils
          from pcluster.api import encoder
          from pcluster.cli.exceptions import APIOperationException, ParameterException
          from pcluster.api.errors import exception_message, NotFoundException
          import pcluster.lib as pc

          crhelper_path = "/opt/python/pcluster/resources/custom_resources/custom_resources_code"
          sys.path.insert(0, crhelper_path)
          from crhelper import CfnResource
          helper = CfnResource()

          def drop_keys(_dict, keys):
              return {k: v for k, v in _dict.items() if k not in keys}

          def flatten(obj, ret={}, path=""):
              """flatten a nested map using dot-notation for keys."""
              if isinstance(obj, list):  # convert list to dictionary for flattening
                  return flatten({str(i): v for i, v in enumerate(obj)}, ret, path)
              for k, v in obj.items():
                  if isinstance(v, (dict, list)):  # recurse on complex objects
                      flatten(v, ret, f"{path}{k}.")
                  else:  # otherwise add with prefix
                      ret[path + str(k)] = v
              return ret

          def update_response(data):
              logger.info(data)
              # Avoid limit on response object size, user has provided these, so drop them in the response
              extra_keys = {"clusterConfiguration", "scheduler", "tags"}
              # create / delete responses have cluster information nested in "cluster" key,
              # flatten that portion while keeping other keys to propagate warnings.
              if "cluster" in data:
                  helper.Data.update(flatten(drop_keys(data["cluster"], extra_keys)))

                  validation_messages = json.dumps(data.get("validationMessages", []))
                  validation_messages = "TRUNCATED:" + validation_messages[:2048] if len(validation_messages) > 2048 else validation_messages
                  helper.Data["validationMessages"] = validation_messages
              else:  # without "cluster" in the keys, this is a cluster object.
                  helper.Data.update(flatten(drop_keys(data, extra_keys)))

          def serialize(val):
              return utils.to_iso_timestr(val) if isinstance(val, datetime.date) else val

          def get_stack_tags(stack_name, overrides):
              cfn = boto3.client('cloudformation')
              stack_tags = cfn.describe_stacks(StackName=stack_name)["Stacks"][0].get("Tags", [])
              return list(filter(lambda t: not (t["Key"].startswith("aws:") or t["Key"] in overrides), stack_tags))

          def create_or_update(event):
              properties = event["ResourceProperties"]
              full_event = json.loads(boto3.client("s3").get_object(Bucket="${PclusterCustomResourceBucket}",Key=properties.get("ClusterName")+"/event.json")["Body"].read())
              cluster_configuration = full_event["ResourceProperties"]["ClusterConfiguration"]
              request_type = event["RequestType"].upper()
              helper.Data["validationMessages"] = "[]"  # default value

              if properties.get("DeletionPolicy", "Delete") not in {"Retain", "Delete"}:
                  raise ValueError("DeletionPolicy must be one of [\"Retain\", \"Delete\"].")
              if request_type == "CREATE" and "ClusterName" not in properties:
                  raise ValueError("Couldn't find a ClusterName in the properties.")
              elif request_type == "UPDATE" and event["PhysicalResourceId"] != properties.get("ClusterName"):
                  raise ValueError("Cannot update the ClusterName in the properties.")

              cluster_name = properties["ClusterName"]
              logger.info(f"{event['RequestType'].upper()}: {cluster_name}")
              physical_resource_id = cluster_name

              try:
                  meta_keys = {"ServiceToken", "DeletionPolicy"}
                  kwargs = {**{pcluster.utils.to_snake_case(k): serialize(v) for k, v in drop_keys(properties, meta_keys).items()}, "wait": False}
                  kwargs["cluster_configuration"] = cluster_configuration
                  resource_tags = [{"Key": "parallelcluster:custom_resource", "Value": "cluster"}]
                  config_tags = cluster_configuration.get("Tags", [])
                  stack_tags = get_stack_tags(event['StackId'], {t["Key"] for t in config_tags})
                  kwargs["cluster_configuration"]["Tags"] = stack_tags + config_tags + resource_tags
                  func = {"CREATE": pc.create_cluster, "UPDATE": pc.update_cluster}[request_type]
                  update_response(func(**kwargs))
              except (APIOperationException, ParameterException, TypeError)  as e:
                  logger.info(str(e))
                  raise ValueError(str(e))
              except Exception as e:
                  message = pcluster.api.errors.exception_message(e)
                  # StatusReason is truncated, so skip changeset in output, still logged below
                  block_list = {"change_set"}
                  message_data = drop_keys(message.to_dict(), block_list)
                  logger.info(message_data)

                  # sort more critical errors last
                  if "configuration_validation_errors" in message_data and message_data["configuration_validation_errors"]:
                      order = {k: i for i, k in enumerate(["INFO", "WARNING", "ERROR"])}
                      message_data["configuration_validation_errors"].sort(key=lambda e: order[e["level"]])

                  str_msg = encoder.JSONEncoder().encode(message_data)
                  if not re.search(r"No changes found", str_msg):
                      logger.info(encoder.JSONEncoder().encode(message))
                      raise ValueError(str_msg)
                  logger.info(f"No changes found to update: {cluster_name}")

              return physical_resource_id

          @helper.create
          def create(event, context):
              return create_or_update(event)

          @helper.update
          def update(event, context):
              return create_or_update(event)

          @helper.delete
          def delete(event, context):
              properties = event["ResourceProperties"]
              cluster_name = properties.get("ClusterName")

              boto3.resource('s3').Bucket("${PclusterCustomResourceBucket}").objects.filter(Prefix=f"{cluster_name}/").delete()

              deletion_policy = properties.get("DeletionPolicy", "Delete")
              if deletion_policy not in {"Retain", "Delete"}:
                  raise ValueError("DeleetionPolicy must be one of [\"Retain\", \"Delete\"].")
              if deletion_policy == "Retain":
                  return cluster_name

              logger.info(f"Deleting: {cluster_name}")
              try:
                  update_response(pc.delete_cluster(cluster_name=cluster_name))
              except (ParameterException, NotFoundException): # cluster deleted or invalid name -- ignore here.
                  pass
              except Exception as e:
                  message = exception_message(e)
                  raise ValueError(encoder.JSONEncoder().encode(message))

          # Polling functionality for async CUD operations

          def poll(event):
              log_group = os.getenv("AWS_LAMBDA_LOG_GROUP_NAME")
              cluster_name = event["ResourceProperties"].get("ClusterName")
              try:
                  cluster = pc.describe_cluster(cluster_name=cluster_name)
                  status = cluster.get("clusterStatus")

                  if status in {"CREATE_COMPLETE", "UPDATE_COMPLETE"}:
                      update_response(cluster)
                      return cluster_name
                  elif status in {"CREATE_FAILED", "UPDATE_FAILED", "DELETE_FAILED"}:
                      reasons = ",".join(f["failureCode"] for f in cluster.get("failures", []))
                      raise ValueError(f"{cluster_name}: {reasons} (LogGroup: {log_group})")

              # If create fails and we try to roll-back (e.g. delete),
              # gracefully handle missing cluster. on the delete pathway, the
              # only invalid parameter can be the name
              except (ParameterException, NotFoundException):
                  if event["RequestType"].upper() == "DELETE":
                      # Returning a value here signifies that the delete is completed and we can stop polling
                      # not returning a value here causes cfn resource helper to keep polling.
                      return cluster_name
                  raise ValueError(f"{cluster_name} failed {event['RequestType'].upper()}. See LogGroup: {log_group}")

          @helper.poll_create
          def poll_create(event, context):
              return poll(event)

          @helper.poll_update
          def poll_update(event, context):
              return poll(event)

          @helper.poll_delete
          def poll_delete(event, context):
              return poll(event)

          def handler(event, context):
              try:
                  logger.info("Beginning of Pcluster custom resource Lambda function. Printing full event...")
                  logger.info(event)
                  if event["ResourceProperties"].get("ClusterConfiguration") or (event.get("OldResourceProperties") and event["OldResourceProperties"].get("ClusterConfiguration")):
                      boto3.client('s3').put_object(
                          Body=json.dumps(event),
                          Bucket="${PclusterCustomResourceBucket}",
                          Key=event["ResourceProperties"].get("ClusterName")+"/event.json"
                      )
                      event["ResourceProperties"].pop("ClusterConfiguration", None)
                      event.get("OldResourceProperties", {}).pop("ClusterConfiguration", None)
              except Exception as exception:
                  cfnresponse.send(event, context, cfnresponse.FAILED, {}, event.get('PhysicalResourceId', 'PclusterClusterCustomResource'), str(exception))

              helper(event, context)


  ######### cluster
  PclusterCluster:
    Type: Custom::PclusterCluster
    Properties:
      ServiceToken: !GetAtt PclusterCfnFunction.Arn
      ClusterName: !Ref ClusterName
      ClusterConfiguration:
        Image:
          Os: ubuntu2004
          CustomAmi: !Ref CustomAmiId
        HeadNode:
          InstanceType: !Ref HeadNodeInstanceType
          Networking:
            SubnetId: !Ref FirstAZPrivateSubnetId
            ElasticIp: false
            SecurityGroups:
            - !Ref DatabaseClientSecGroup
            - !Ref HeadNodeSecGroup
            - !Ref VizBackendSecGroup
          Ssh:
            KeyName: !Ref KeyName
          LocalStorage:
            RootVolume:
              Size: !Ref HeadNodeRootVolumeSize
              Encrypted: !Ref HeadNodeRootVolumeEncrypted
              VolumeType: !Ref HeadNodeRootVolumeType
              DeleteOnTermination: true
            EphemeralVolume:
              MountDir: /scratch
          CustomActions:
            OnNodeConfigured:
              Script: !Ref ScriptUrl
          Iam:
            AdditionalIamPolicies:
              - Policy: !Sub arn:${AWS::Partition}:iam::aws:policy/AmazonSSMManagedInstanceCore
        DirectoryService:
          DomainName: !Ref ADDomain
          DomainAddr: !Ref ADAddr
          PasswordSecretArn: !Ref ADPasswordSecretArn
          DomainReadOnlyUser: !Ref ADReadonlyUser
          LdapTlsReqCert: never

        SharedStorage:
        - MountDir: /nfs
          Name: projects
          StorageType: Efs
          EfsSettings:
            FileSystemId: !Ref EFSFileSystemId
        Scheduling:
          Scheduler: slurm
          SlurmSettings:
            QueueUpdateStrategy: TERMINATE
            Database:
              Uri: !Ref DatabaseUri
              UserName: !Ref DatabaseAdmin
              PasswordSecretArn: !Ref DatabasePasswordSecretArn

          SlurmQueues:
          - Name: master
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
              - !Ref ComputeNodeSecGroup
              - !Ref DatabaseClientSecGroup
              - !Ref VizBackendSecGroup
            ComputeResources:
            - Name: "cpu"
              Instances:
                 - InstanceType: t2.medium
              MinCount: 0
              MaxCount: 100
          - Name: cpu-spot
            CapacityType: SPOT
            AllocationStrategy: lowest-price
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
              - !Ref ComputeNodeSecGroup
              - !Ref DatabaseClientSecGroup
              - !Ref VizBackendSecGroup
            ComputeSettings:
              LocalStorage:
                RootVolume:
                  Size: !Ref ComputeNodeRootVolumeSize
                  Encrypted: !Ref ComputeNodeRootVolumeEncrypted
                  VolumeType: !Ref ComputeNodeRootVolumeType
                EphemeralVolume:
                  MountDir: /scratch
            ComputeResources:
            - Name: "cpu"
              Instances:
                 - InstanceType: !Ref CpuQueueNodeType
              MinCount: 0
              MaxCount: !Ref CpuQueueNodesMax
          - Name: cpu
            CapacityType: ONDEMAND
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
                - !Ref ComputeNodeSecGroup
                - !Ref DatabaseClientSecGroup
                - !Ref VizBackendSecGroup
            ComputeResources:
              - Name: "cpu"
                Instances:
                  - InstanceType: !Ref CpuQueueNodeType
                MinCount: 0
                MaxCount: !Ref CpuQueueNodesMax

          - Name: lightgpu-spot
            CapacityType: SPOT
            AllocationStrategy: lowest-price
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
              - !Ref ComputeNodeSecGroup
              - !Ref DatabaseClientSecGroup
              - !Ref VizBackendSecGroup
            ComputeSettings:
              LocalStorage:
                RootVolume:
                  Size: !Ref ComputeNodeRootVolumeSize
                  Encrypted: !Ref ComputeNodeRootVolumeEncrypted
                  VolumeType: !Ref ComputeNodeRootVolumeType
                EphemeralVolume:
                  MountDir: /scratch
            ComputeResources:
            - Name: "gpu"
              Instances:
                - InstanceType: !Ref LightGpuQueueNodeType
              MinCount: 0
              MaxCount: !Ref LightGpuQueueNodesMax
          - Name: lightgpu
            CapacityType: ONDEMAND
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
                - !Ref ComputeNodeSecGroup
                - !Ref DatabaseClientSecGroup
                - !Ref VizBackendSecGroup
            ComputeResources:
              - Name: "gpu"
                Instances:
                  - InstanceType: !Ref LightGpuQueueNodeType
                MinCount: 0
                MaxCount: !Ref LightGpuQueueNodesMax

          - Name: "project-spot"
            CapacityType: SPOT
            AllocationStrategy: lowest-price
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
              - !Ref ComputeNodeSecGroup
              - !Ref DatabaseClientSecGroup
              - !Ref VizBackendSecGroup
            ComputeSettings:
              LocalStorage:
                RootVolume:
                  Size: !Ref ComputeNodeRootVolumeSize
                  Encrypted: !Ref ComputeNodeRootVolumeEncrypted
                  VolumeType: !Ref ComputeNodeRootVolumeType
                EphemeralVolume:
                  MountDir: /scratch
            ComputeResources:
            - Name: "cpu"
              Instances:
                - InstanceType: !Ref ProjectQueueCpuNodeType
              MinCount: 0
              MaxCount: !Ref ProjectQueueCpuNodesMax
            - Name: "gpu"
              Instances:
                - InstanceType: !Ref ProjectQueueGpuNodeType
              MinCount: 0
              MaxCount: !Ref ProjectQueueGpuNodesMax
          - Name: "project"
            CapacityType: ONDEMAND
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
              - !Ref ComputeNodeSecGroup
              - !Ref DatabaseClientSecGroup
              - !Ref VizBackendSecGroup
            ComputeSettings:
              LocalStorage:
                RootVolume:
                  Size: !Ref ComputeNodeRootVolumeSize
                  Encrypted: !Ref ComputeNodeRootVolumeEncrypted
                  VolumeType: !Ref ComputeNodeRootVolumeType
                EphemeralVolume:
                  MountDir: /scratch
            ComputeResources:
            - Name: "cpu"
              Instances:
                - InstanceType: !Ref ProjectQueueCpuNodeType
              MinCount: 0
              MaxCount: !Ref ProjectQueueCpuNodesMax
            - Name: "gpu"
              Instances:
                - InstanceType: !Ref ProjectQueueGpuNodeType
              MinCount: 0
              MaxCount: !Ref ProjectQueueGpuNodesMax

            # Image:
            #   CustomAmi: !Ref CustomAmiId


          - Name: "debug"
            CapacityType: SPOT
            AllocationStrategy: lowest-price
            Networking:
              SubnetIds: !Split [ ",", !Ref ComputeNodeSubnets ]
              SecurityGroups:
              - !Ref ComputeNodeSecGroup
              - !Ref DatabaseClientSecGroup
              - !Ref VizBackendSecGroup
            ComputeSettings:
              LocalStorage:
                RootVolume:
                  Size: !Ref ComputeNodeRootVolumeSize
                  Encrypted: !Ref ComputeNodeRootVolumeEncrypted
                  VolumeType: !Ref ComputeNodeRootVolumeType
                EphemeralVolume:
                  MountDir: /scratch
            ComputeResources:
            - Name: "cpu"
              Instances:
                 - InstanceType: !Ref DebugQueueCPUNodeType
              MinCount: 0
              MaxCount: !Ref DebugQueueCPUNodesMax
              #SpotPrice: !Ref AWS::NoValue
            - Name: "gpu"
              Instances:
                - InstanceType: !Ref DebugQueueGPUNodeType
              MinCount: 0
              MaxCount: !Ref DebugQueueGPUNodeMax
              #SpotPrice: !Ref AWS::NoValue

            # Image:
            #   CustomAmi: !Ref CustomAmiId


Outputs:
  PclusterCustomResourceBucket:
    Value: !Ref PclusterCustomResourceBucket

  HeadnodePrivateIP:
    Value: !GetAtt [ PclusterCluster, headNode.privateIpAddress ]

  CloudwatchDashboardUrl:
    Value: !Sub
      - https://console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#dashboards/dashboard/${ClName}-${AWS::Region}
      - { ClName: !Ref ClusterName }

  SystemManagerUrl:
    Description: URL to access the HeadNode via SystemManager
    Value: !Sub
      - https://${ConsoleDomain}/systems-manager/session-manager/${InstanceId}?region=${AWS::Region}
      - { ConsoleDomain: !If [ GovCloud, 'console.amazonaws-us-gov.com', !If [ China, 'console.amazonaws.cn', !Sub '${AWS::Region}.console.aws.amazon.com']],
          InstanceId: !GetAtt [ PclusterCluster, headNode.instanceId ]
        }
